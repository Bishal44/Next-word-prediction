{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "50eb1355",
   "metadata": {
    "id": "50eb1355"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-23 22:59:54.109983: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from bs4 import BeautifulSoup\n",
    "import string\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.models import load_model\n",
    "from keras.layers.core import Dense, Activation\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.utils import to_categorical\n",
    "import pickle\n",
    "from keras.optimizers import RMSprop\n",
    "import numpy as np\n",
    "from numpy import array\n",
    "import heapq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nXwmMiUHVmN1",
   "metadata": {
    "id": "nXwmMiUHVmN1"
   },
   "source": [
    "**Import data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0f4c486",
   "metadata": {
    "id": "b0f4c486"
   },
   "outputs": [],
   "source": [
    "documents = []\n",
    "for file in os.listdir(\"reuters_sample/\"): # original: \"reuters_data/\"\n",
    "    if file.endswith('.sgm'): # it is important for GoogleColab\n",
    "        filename = os.path.join(\"reuters_sample\", file) # original: \"reuters_data\"\n",
    "        f = open(filename, 'r', encoding='utf-8', errors='ignore')\n",
    "        dataFile = f.read().lower()\n",
    "        \n",
    "        soup = BeautifulSoup(dataFile, 'html.parser')\n",
    "\n",
    "        ## get all 'topic'\n",
    "        # topics = {topic.name for topic in soup.find_all()}\n",
    "  \n",
    "        ## iterate all 'topic'\n",
    "        # for topic in topics:\n",
    "          \n",
    "        ## find all element of 'topic'\n",
    "          # for i in soup.find_all('topic'):\n",
    "  \n",
    "        ## if tag has attribute of class\n",
    "            # if i.has_attr('trade'):\n",
    "  \n",
    "# We have selected the following 20 'TOPICS' out of 135:\n",
    "# that we want to use for our prediction exercise: 1.) \"trade\" 2.) \"earn\" 3.) \"grain\" 4.) \"money-fx\" 5.) \n",
    "# \"coffee\" 6.) \"gold\" 7.) \"acq\" 8.) \"wheat\" 9.) \"veg-oil\" 10.) \"nat-gas\" 11.) \"cooper\" 12.) \"ship\" 13.) \n",
    "# \"dlr\" 14.) \"crude\" 15.) \"interest\" 16.) \"meal-feed\" 17.) \"alum\" 18.) \"money-supply\" 19.) \"cocoa\" 20.) \"livestock\"\n",
    "        contents = soup.findAll('title')\n",
    "        \n",
    "        for content in contents:\n",
    "            documents.append(content.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "jwFHnhJ6YrPG",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jwFHnhJ6YrPG",
    "outputId": "d769a4f3-c6cf-427b-a14c-8aff14712298"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents: 7958\n"
     ]
    }
   ],
   "source": [
    "print('Number of documents: {}'.format(len(documents)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "BwkB00Xzx-vT",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BwkB00Xzx-vT",
    "outputId": "96174c3f-7547-410f-e863-1e685dd209ce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents: 7693\n"
     ]
    }
   ],
   "source": [
    "# Remove duplicated strings from the list of strings\n",
    "documents = [i for n, i in enumerate(documents) if i not in documents[:n]]\n",
    "\n",
    "print('Number of documents: {}'.format(len(documents)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f9549e3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2f9549e3",
    "outputId": "34adf071-e76d-4a8a-da33-599a658dc082"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['inco sees no major impact from dow removal',\n",
       " 'former empire of carolina <emp> exec sentenced',\n",
       " 'doctors find link between aids, smallpox virus',\n",
       " 'birth control pills help prevent cancer - study',\n",
       " 'u.s. economic data key to debt futures outlook',\n",
       " 'u.s. \"action program\" for sub-saharan africa',\n",
       " 'unusual texas instruments <txn> preferred priced',\n",
       " 'clark says he expects u.s. action on acid rain',\n",
       " 'ford motor <f> distributes profit sharing',\n",
       " 'jamaica puts cap on borrowing']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fRsdiodgY4er",
   "metadata": {
    "id": "fRsdiodgY4er"
   },
   "source": [
    "**Join the documents**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e5894ab",
   "metadata": {
    "id": "9e5894ab"
   },
   "outputs": [],
   "source": [
    "data = \"\"\n",
    "for d in documents:\n",
    "    data += d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a3a635c4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a3a635c4",
    "outputId": "2f6d665d-70bb-408a-ead2-2c2cf4bc68ca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of data: 347403\n"
     ]
    }
   ],
   "source": [
    "print('Number of data: {}'.format(len(data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3ffe6795",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3ffe6795",
    "outputId": "5cd35f61-cdbd-4e69-9b9c-57b0e2a101e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of data: 346768\n",
      "inco sees no major impact from dow removalformer empire of carolina <emp> exec sentenceddoctors find\n"
     ]
    }
   ],
   "source": [
    "# improve punctuation\n",
    "data = data.replace('\\n', '').replace('\\r', '').replace('\\ufeff', '')\n",
    "print('Number of data: {}'.format(len(data)))\n",
    "print(data[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "CNRiSJsMtwQu",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CNRiSJsMtwQu",
    "outputId": "6041d359-b0ae-4595-b68e-1b311d10f968"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inco sees no major impact from dow removalformer empire of carolina  emp  exec sentenceddoctors find\n"
     ]
    }
   ],
   "source": [
    "translator = str.maketrans(string.punctuation, ' '*len(string.punctuation)) #map punctuation to space\n",
    "data = data.translate(translator)\n",
    "print(data[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "225b3c6b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "225b3c6b",
    "outputId": "1a2ff1ab-a9ae-4344-d847-44f658e0b0e1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1644, 19, 81, 366, 1094]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# integer encode text\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts([data])\n",
    "encoded_data = tokenizer.texts_to_sequences([data])[0]\n",
    "print(len(encoded_data))\n",
    "encoded_data[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cff5b658",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cff5b658",
    "outputId": "c03f23da-60ed-4603-cbea-8aff102dcbe1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary Size: 14407\n"
     ]
    }
   ],
   "source": [
    "# determine the vocabulary size\n",
    "# unique_words = tokenizer.word_index\n",
    "unique_words = np.unique(encoded_data)\n",
    "vocab_size = len(unique_words) + 1  # 0 is reserved for padding so that's why we added 1\n",
    "unique_word_index = dict((c, i) for i, c in enumerate(unique_words))\n",
    "print('Vocabulary Size: %d' % vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "PYLR_W62b3lm",
   "metadata": {
    "id": "PYLR_W62b3lm"
   },
   "source": [
    "**Next, we need to create sequences of words to fit the model with one word as input and one word as output.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "858f3ef5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "858f3ef5",
    "outputId": "081afb86-cef0-4f9a-aeb0-f3009d000afe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19, 81, 366, 1094, 46]\n",
      "470\n"
     ]
    }
   ],
   "source": [
    "# create word -> word sequences\n",
    "WORD_LENGTH = 5\n",
    "prev_words = []\n",
    "next_words = []\n",
    "for i in range(1, len(encoded_data) - WORD_LENGTH):\n",
    "    prev_words.append(encoded_data[i:i + WORD_LENGTH])\n",
    "    next_words.append(encoded_data[i + WORD_LENGTH])\n",
    "print(prev_words[0])\n",
    "print(next_words[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "uiJwfjRM1WYf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uiJwfjRM1WYf",
    "outputId": "0f0818de-4d88-46a2-b574-05bd5248a59e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Sequences: 51494\n"
     ]
    }
   ],
   "source": [
    "print('Total Sequences: %d' % len(prev_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "MNb-LdgdcqSZ",
   "metadata": {
    "id": "MNb-LdgdcqSZ"
   },
   "outputs": [],
   "source": [
    "# list(len(prev_words)[:5]) # [input, output]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "kMClupvlcdWq",
   "metadata": {
    "id": "kMClupvlcdWq"
   },
   "source": [
    "\n",
    "\n",
    "**We can then split the sequences into input (X) and output elements (y)**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f0fb1be0",
   "metadata": {
    "id": "f0fb1be0"
   },
   "outputs": [],
   "source": [
    "# split into X and y elements\n",
    "X = prev_words\n",
    "X = np.array(X)\n",
    "Y = next_words\n",
    "Y = np.array(Y)\n",
    "\n",
    "# X = np.zeros((len(prev_words), WORD_LENGTH, vocab_size), dtype=bool)\n",
    "# Y = np.zeros((len(next_words), vocab_size), dtype=bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6f323b68",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6f323b68",
    "outputId": "73f8a8cd-1298-49d6-810a-6f761e07d1a6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  19   81  366 1094   46]\n",
      " [  81  366 1094   46  470]\n",
      " [ 366 1094   46  470 3706]\n",
      " [1094   46  470 3706 3707]\n",
      " [  46  470 3706 3707    8]]\n",
      "[ 470 3706 3707    8 1645]\n"
     ]
    }
   ],
   "source": [
    "print(X[:5])\n",
    "print(Y[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "101d961d",
   "metadata": {
    "id": "101d961d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# one hot encode outputs\n",
    "Y = to_categorical(Y, num_classes=vocab_size)\n",
    "# define model\n",
    "Y[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ALNxgolmIFBD",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ALNxgolmIFBD",
    "outputId": "2fb2c8a3-ff8d-486e-efdd-6d73ea69d674"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(51494, 14407)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape\n",
    "Y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9-SgDZVKd_IL",
   "metadata": {
    "id": "9-SgDZVKd_IL"
   },
   "source": [
    "**Build the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b459da0b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b459da0b",
    "outputId": "f688e5bf-e3e2-4e51-dd78-83982df6c178"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-23 23:00:34.899750: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 1, 10)             144070    \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 32)                5504      \n",
      "                                                                 \n",
      " dense (Dense)               (None, 14407)             475431    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 625,005\n",
      "Trainable params: 625,005\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 10, input_length=1)) # original: 5\n",
    "model.add(LSTM(32))\n",
    "model.add(Dense(vocab_size, activation='softmax'))\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "F1eNfS9cebdM",
   "metadata": {
    "id": "F1eNfS9cebdM"
   },
   "source": [
    "**Train the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "Pjty_axoePeu",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Pjty_axoePeu",
    "outputId": "6ab68fe8-b418-473e-8863-440f6983ffe2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/32\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name='embedding_input'), name='embedding_input', description=\"created by layer 'embedding_input'\"), but it was called on an input with incompatible shape (None, 5).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name='embedding_input'), name='embedding_input', description=\"created by layer 'embedding_input'\"), but it was called on an input with incompatible shape (None, 5).\n",
      "1610/1610 [==============================] - 32s 17ms/step - loss: 8.3640 - accuracy: 0.0288\n",
      "Epoch 2/32\n",
      "1610/1610 [==============================] - 29s 18ms/step - loss: 7.8093 - accuracy: 0.0389\n",
      "Epoch 3/32\n",
      "1610/1610 [==============================] - 26s 16ms/step - loss: 7.5961 - accuracy: 0.0454\n",
      "Epoch 4/32\n",
      "1610/1610 [==============================] - 26s 16ms/step - loss: 7.3970 - accuracy: 0.0559\n",
      "Epoch 5/32\n",
      "1610/1610 [==============================] - 27s 17ms/step - loss: 7.1846 - accuracy: 0.0671\n",
      "Epoch 6/32\n",
      "1610/1610 [==============================] - 27s 17ms/step - loss: 6.9718 - accuracy: 0.0778\n",
      "Epoch 7/32\n",
      "1610/1610 [==============================] - 27s 17ms/step - loss: 6.7511 - accuracy: 0.0874\n",
      "Epoch 8/32\n",
      "1610/1610 [==============================] - 29s 18ms/step - loss: 6.5257 - accuracy: 0.0959\n",
      "Epoch 9/32\n",
      "1610/1610 [==============================] - 32s 20ms/step - loss: 6.3079 - accuracy: 0.1035\n",
      "Epoch 10/32\n",
      "1610/1610 [==============================] - 29s 18ms/step - loss: 6.1037 - accuracy: 0.1130\n",
      "Epoch 11/32\n",
      "1610/1610 [==============================] - 19s 12ms/step - loss: 5.9176 - accuracy: 0.1205\n",
      "Epoch 12/32\n",
      "1610/1610 [==============================] - 17s 11ms/step - loss: 5.7421 - accuracy: 0.1284\n",
      "Epoch 13/32\n",
      "1610/1610 [==============================] - 17s 11ms/step - loss: 5.5762 - accuracy: 0.1372\n",
      "Epoch 14/32\n",
      "1610/1610 [==============================] - 17s 11ms/step - loss: 5.4182 - accuracy: 0.1455\n",
      "Epoch 15/32\n",
      "1610/1610 [==============================] - 16s 10ms/step - loss: 5.2662 - accuracy: 0.1550\n",
      "Epoch 16/32\n",
      "1610/1610 [==============================] - 16s 10ms/step - loss: 5.1175 - accuracy: 0.1646\n",
      "Epoch 17/32\n",
      "1610/1610 [==============================] - 19s 12ms/step - loss: 4.9750 - accuracy: 0.1751\n",
      "Epoch 18/32\n",
      "1610/1610 [==============================] - 18s 11ms/step - loss: 4.8372 - accuracy: 0.1866\n",
      "Epoch 19/32\n",
      "1610/1610 [==============================] - 20s 12ms/step - loss: 4.7032 - accuracy: 0.1996\n",
      "Epoch 20/32\n",
      "1610/1610 [==============================] - 22s 14ms/step - loss: 4.5743 - accuracy: 0.2105\n",
      "Epoch 21/32\n",
      "1610/1610 [==============================] - 21s 13ms/step - loss: 4.4480 - accuracy: 0.2256\n",
      "Epoch 22/32\n",
      "1610/1610 [==============================] - 25s 16ms/step - loss: 4.3243 - accuracy: 0.2399\n",
      "Epoch 23/32\n",
      "1610/1610 [==============================] - 25s 16ms/step - loss: 4.2089 - accuracy: 0.2536\n",
      "Epoch 24/32\n",
      "1610/1610 [==============================] - 27s 17ms/step - loss: 4.0955 - accuracy: 0.2695\n",
      "Epoch 25/32\n",
      "1610/1610 [==============================] - 26s 16ms/step - loss: 3.9881 - accuracy: 0.2850\n",
      "Epoch 26/32\n",
      "1610/1610 [==============================] - 26s 16ms/step - loss: 3.8809 - accuracy: 0.3018\n",
      "Epoch 27/32\n",
      "1610/1610 [==============================] - 27s 17ms/step - loss: 3.7803 - accuracy: 0.3181\n",
      "Epoch 28/32\n",
      "1610/1610 [==============================] - 26s 16ms/step - loss: 3.6823 - accuracy: 0.3342\n",
      "Epoch 29/32\n",
      "1610/1610 [==============================] - 26s 16ms/step - loss: 3.5903 - accuracy: 0.3487\n",
      "Epoch 30/32\n",
      "1610/1610 [==============================] - 27s 17ms/step - loss: 3.4991 - accuracy: 0.3675\n",
      "Epoch 31/32\n",
      "1610/1610 [==============================] - 27s 17ms/step - loss: 3.4150 - accuracy: 0.3807\n",
      "Epoch 32/32\n",
      "1610/1610 [==============================] - 26s 16ms/step - loss: 3.3320 - accuracy: 0.3959\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe5afc85430>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit network\n",
    "optimizer = RMSprop(learning_rate=0.01)\n",
    "\n",
    "# compile network\n",
    "#### since labels are INTEGERS, we need to changed from loss='categorical_crossentropy'!!!\n",
    "#### If you want to provide labels using one-hot representation, please use CategoricalCrossentropy loss.\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy']) # optimizer ='adam'\n",
    "model.fit(X, Y, epochs=32)\n",
    "\n",
    "## Alternative versions\n",
    "# history = model.fit(X, Y, validation_split=0.05, batch_size=50, epochs=20, shuffle=True).history\n",
    "# history = model.fit(X, Y, validation_split=0.05, batch_size=50, epochs=20, shuffle=True).history\n",
    "# model.fit(X, Y, epochs=100)\n",
    "# model.fit(X, y, epochs=150, batch_size=64, callbacks=[checkpoint, reduce, tensorboard_Visualization])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "QxgsBCrwtECi",
   "metadata": {
    "id": "QxgsBCrwtECi"
   },
   "source": [
    "**Save trained model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "A2ioJcaGtEN4",
   "metadata": {
    "id": "A2ioJcaGtEN4"
   },
   "outputs": [],
   "source": [
    "# After successful training, we will save the trained model and just load it back as needed.\n",
    "model.save('keras_next_word_model_epoch32.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "sI9KkPwTL3ee",
   "metadata": {
    "id": "sI9KkPwTL3ee"
   },
   "outputs": [],
   "source": [
    "#pickle.dump(history, open(\"history.p\", \"wb\"))\n",
    "model = load_model('keras_next_word_model_epoch32.h5')\n",
    "history = pickle.load(open(\"history.p\", \"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "XsrX16ketfZq",
   "metadata": {
    "id": "XsrX16ketfZq"
   },
   "source": [
    "**Prediction**\n",
    "Using saved model:\n",
    "- we input the sample as a feature vector\n",
    "- we convert the input string to a single feature vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4UPDwpgBtfkF",
   "metadata": {
    "id": "4UPDwpgBtfkF"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hospital\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'hospital'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[0;32mIn [24]\u001b[0m, in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m         x[\u001b[38;5;241m0\u001b[39m, t, unique_word_index[word]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n\u001b[0;32m----> 7\u001b[0m \u001b[43mprepare_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mHOSPITAL CORP SAYS IT RECEIVED 47 DLR A SHARE OFFER FROM INVESTOR GROUP\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlower\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [24]\u001b[0m, in \u001b[0;36mprepare_input\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t, word \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(text\u001b[38;5;241m.\u001b[39msplit()):\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(word)\n\u001b[0;32m----> 5\u001b[0m     x[\u001b[38;5;241m0\u001b[39m, t, \u001b[43munique_word_index\u001b[49m\u001b[43m[\u001b[49m\u001b[43mword\u001b[49m\u001b[43m]\u001b[49m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "\u001b[0;31mKeyError\u001b[0m: 'hospital'"
     ]
    }
   ],
   "source": [
    "def prepare_input(text):\n",
    "    x = np.zeros((1, WORD_LENGTH, vocab_size))\n",
    "    for t, word in enumerate(text.split()):\n",
    "        print(word)\n",
    "        x[0, t, unique_word_index[word]] = 1\n",
    "    return x\n",
    "prepare_input(\"HOSPITAL CORP SAYS IT RECEIVED 47 DLR A SHARE OFFER FROM INVESTOR GROUP\".lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fmfAeTHUt5aL",
   "metadata": {
    "id": "fmfAeTHUt5aL"
   },
   "outputs": [],
   "source": [
    "# To choose the best possible \"n\" words after the prediction from the model ...\n",
    "def sample(preds, top_n=3):\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds)\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    return heapq.nlargest(top_n, range(len(preds)), preds.take)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "r75h3atZuDxS",
   "metadata": {
    "id": "r75h3atZuDxS"
   },
   "outputs": [],
   "source": [
    "# Use the function predict_completions to predict and return the list of \"n\" predicted words.\n",
    "def predict_completions(text, n=3):\n",
    "    if text == \"\":\n",
    "        return(\"0\")\n",
    "    x = prepare_input(text)\n",
    "    preds = model.predict(x, verbose=0)[0]\n",
    "    next_indices = sample(preds, n)\n",
    "    return [unique_words[idx] for idx in next_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Cv5GjUyDuaNp",
   "metadata": {
    "id": "Cv5GjUyDuaNp"
   },
   "outputs": [],
   "source": [
    "# We use tokenizer.tokenize fo removing the punctuations and also we choose 5 first words because our predicts base on 5 previous words.\n",
    "\n",
    "q =  \"GILLETTE CANADA ISSUES 70 MLN STG BOND\"\n",
    "\n",
    "## 20 EXAMPLES FOR EVALUATION:\n",
    "\"\"\"\n",
    "'AMES DEPARTMENT STORE <ADD> MARCH SALES UP'\n",
    "'ISRAELI HELICOPTERS RAID SOUTH LEBANON - RADIO'\n",
    "'GILLETTE CANADA ISSUES 70 MLN STG BOND'\n",
    "'DIGITAL COMMUNICATIONS <DCAI> SELLS SWITCHES'\n",
    "'ITALIAN TREASURY BILL OFFER MEETS MIXED DEMAND'\n",
    "'WESTLAND TO CUT A THIRD OF HELICOPTER WORKFORCE'\n",
    "'USDA DETAILS FREE GRAIN STOCKS UNDER LOAN'\n",
    "'FED SAYS U.S. DISCOUNT WINDOW BORROWINGS 361 MLN DLRS IN APRIL 8 WEEK'\n",
    "'HOSPITAL CORP SAYS IT RECEIVED 47 DLR A SHARE OFFER FROM INVESTOR GROUP'\n",
    "'FED SEEN BUYING DOLLARS FOR YEN IN OPEN MARKET'\n",
    "'DOLLAR ENDS LOWER IN LACKLUSTRE FRANKFURT'\n",
    "'HEALTH AND REHABILITATION <HRP> INITIAL PAYOUT'\n",
    "'SUPERMARKETS GENERAL <SGL> FIVE WEEK SALES'\n",
    "'SEKISUI CHEMICAL ISSUES EQUITY WARRANT EUROBOND'\n",
    "'WEST GERMAN BEET PLANTINGS DELAYED THREE WEEKS'\n",
    "'BURMAH OIL PROSPECTS REMAIN FAVOURABLE'\n",
    "'PARKER DRILLING CO <PKD> 2ND QTR FEB 28 LOSS'\n",
    "'TURKEY CALLS FOR DIALOGUE TO SOLVE DISPUTE'\n",
    "'INVESTMENT TECHNOLOGIES <IVES> IN REBATE PACT'\n",
    "'ENTOURAGE <ENTG> HAS FIRST QUARTER LOSS'\n",
    "\"\"\"\n",
    "\n",
    "print(\"correct sentence: \",q)\n",
    "seq = \" \".join(tokenizer.tokenize(q.lower())[0:5])\n",
    "print(\"Sequence: \",seq)\n",
    "print(\"next possible words: \", predict_completions(seq, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "H41rOg1XpXUl",
   "metadata": {
    "id": "H41rOg1XpXUl"
   },
   "source": [
    "**Creating a Prediction script**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "jVlQUV23pa6X",
   "metadata": {
    "id": "jVlQUV23pa6X"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Load the model and tokenizer\n",
    "\n",
    "model = history\n",
    "\n",
    "def Predict_Next_Words(model, tokenizer, text):\n",
    "    \"\"\"\n",
    "        In this function we are using the tokenizer and models trained\n",
    "        and we are creating the sequence of the text entered and then\n",
    "        using our model to predict and return the the predicted word.\n",
    "    \n",
    "    \"\"\"\n",
    "    for i in range(3):\n",
    "        sequence = tokenizer.texts_to_sequences([text])[0]\n",
    "        sequence = np.array(sequence)\n",
    "        \n",
    "        preds = model.predict_classes(sequence)\n",
    "#         print(preds)\n",
    "        predicted_word = \"\"\n",
    "        \n",
    "        for key, value in tokenizer.word_index.items():\n",
    "            if value == preds:\n",
    "                predicted_word = key\n",
    "                break\n",
    "        \n",
    "        print(predicted_word)\n",
    "        return predicted_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "LxZ-ZlCkpgZ0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LxZ-ZlCkpgZ0",
    "outputId": "0c39010f-4520-4860-a51a-3a940d7c23d4"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    We are testing our model and we will run the model\n",
    "    until the user decides to stop the script.\n",
    "    While the script is running we try and check if \n",
    "    the prediction can be made on the text. If no\n",
    "    prediction can be made we just continue.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# text1 = \"at the dull\"\n",
    "# text2 = \"collection of textile\"\n",
    "# text3 = \"what a strenuous\"\n",
    "# text4 = \"stop the script\"\n",
    "\n",
    "while(True):\n",
    "\n",
    "    text = input(\"Enter your line: \")\n",
    "    \n",
    "    if text == \"stop the script\":\n",
    "        print(\"Ending The Program.....\")\n",
    "        break\n",
    "    \n",
    "    else:\n",
    "        try:\n",
    "            text = text.split(\" \")\n",
    "            text = text[-1]\n",
    "\n",
    "            text = ''.join(text)\n",
    "            Predict_Next_Words(model, tokenizer, text)\n",
    "            \n",
    "        except:\n",
    "            continue"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
